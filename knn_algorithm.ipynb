{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad941f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the required modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#Set the input directory containing the parsed data\n",
    "input_directory = './parsed_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e1208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data and add final data enrichment\n",
    "df = pd.read_csv(input_directory+'/data.csv')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['unix_time'],unit='s')\n",
    "df = df.sort_values(by = 'date', ascending = False)\n",
    "\n",
    "df['position'] = df.lon * df.lat\n",
    "df['month'] = df.date.dt.month\n",
    "df['day_of_week'] = df.date.dt.dayofweek\n",
    "\n",
    "df = df[['sensor_id','count', 'unix_time','hour','month','day_of_week','position','date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d2cc2",
   "metadata": {},
   "source": [
    "Test and train data will be split based on sensor ID. We're going to simulate the real world data by removing one sensor worth of data for each fold and then predicting how well the KNN algoritmh performs on this data. This is important as it means that our algorithm won't be able to rely on historical readings from the same location, which is somthing that will be present in the real world data supplied to the algortihm.\n",
    "\n",
    "From the output below, we can observe some 87 folds with varying observation counts per sensor location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6334cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Define k folds based on the sensor numbers\n",
    "sensor_folds = df.groupby(['sensor_id']).count().reset_index().sensor_id.tolist()\n",
    "df.groupby(['sensor_id']).count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aea2b0",
   "metadata": {},
   "source": [
    "To simulate our data environment we need to do the following:\n",
    "- Generate a test set from a single sensor_id location and filter in teh current month only. This is becasue under real conditions we won't have training data from the prior month. Likewise, we won't be predicting congestion for the past.\n",
    "- Filter the training dataset so that it doesn't include the current month, only historical time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab225f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to convert regression outputs into a classificaiton output\n",
    "def convert_to_classification(input_predictions):\n",
    "    output_classes = []\n",
    "\n",
    "    for item in input_predictions:\n",
    "        if item < 180:\n",
    "            output_classes.append('low')           \n",
    "        else:\n",
    "            output_classes.append('high')\n",
    "\n",
    "    return output_classes\n",
    "\n",
    "#Define a function to calcualte precision and recall for a give classification label\n",
    "def precision_recall(true, prediction, label):\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    \n",
    "    for n in range(0, len(true)):\n",
    "        if true[n] != label and prediction[n] != label:\n",
    "            continue\n",
    "        elif true[n] == prediction[n]:\n",
    "            true_positive += 1\n",
    "        elif true[n] == label and prediction[n] != label:\n",
    "            false_negative += 1\n",
    "        elif prediction[n] == label and true[n] != label:\n",
    "            false_positive += 1\n",
    "        \n",
    "        if true_positive + false_negative != 0:\n",
    "            precision = true_positive / (true_positive + false_negative)\n",
    "        else:\n",
    "            precision = 0\n",
    "        \n",
    "        if true_positive + false_positive != 0:\n",
    "            recall = true_positive / (true_positive + false_positive)\n",
    "        else:\n",
    "            recall = 0\n",
    "            \n",
    "    return (precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fefb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "#Keep test samples after this date, keep training samples before this date\n",
    "sample_break_date = '2022/07/01'\n",
    "\n",
    "results_dict = {}\n",
    "\n",
    "#Iterate over each potential value of K\n",
    "for k in range(1,31):\n",
    "    \n",
    "    #For each fold for the given value of K\n",
    "    for fold in sensor_folds:\n",
    "        \n",
    "        #Generate a test and train dataset\n",
    "        train_df = df[df.date < pd.to_datetime('2022/07/01')]\n",
    "        test_df = df[df.date > pd.to_datetime('2022/07/01')]\n",
    "        \n",
    "        X_train = train_df[train_df.sensor_id != fold].drop(['count', 'sensor_id','date'], axis = 1)\n",
    "        X_test = test_df[test_df.sensor_id == fold].drop(['count', 'sensor_id','date'], axis = 1)\n",
    "        \n",
    "        #Skip any folds which are new and don't have more than 30 sampels.\n",
    "        if len(X_test) < 30:\n",
    "            continue\n",
    "        \n",
    "        #Set the y and train and test data\n",
    "        y_train = train_df[train_df.sensor_id != fold]\n",
    "        y_train = y_train['count']\n",
    "\n",
    "        y_test = test_df[test_df.sensor_id == fold]\n",
    "        y_test = y_test['count']\n",
    "        \n",
    "        #Define a scalar to ensure the magnitude differences in the attribtues are reduced\n",
    "        ss = StandardScaler()\n",
    "        \n",
    "        #Transform both the test and train data\n",
    "        X_train = ss.fit_transform(X_train)\n",
    "        X_test = ss.transform(X_test)\n",
    "        \n",
    "        #Create a model and fit on the train data\n",
    "        knn = KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        #Add a new k entry to the results dict if it doesn't already exist\n",
    "        if k not in results_dict:\n",
    "            results_dict[k] = {}\n",
    "        \n",
    "        #Calculate the training error\n",
    "        X_train_prediction = knn.predict(X_train)\n",
    "        X_test_prediction = knn.predict(X_test)\n",
    "        \n",
    "        #Add the results and the relevant metrics to the resutls dict\n",
    "        results_dict[k][fold] = [mean_squared_error(y_train, X_train_prediction, squared = False),\n",
    "                                 mean_squared_error(y_test, X_test_prediction, squared = False),\n",
    "                                accuracy_score(convert_to_classification(input_predictions = y_train), convert_to_classification(input_predictions = X_train_prediction)),\n",
    "                                 accuracy_score( convert_to_classification(input_predictions = y_test), convert_to_classification(input_predictions = X_test_prediction)),\n",
    "                                precision_recall(convert_to_classification(input_predictions = y_test), convert_to_classification(input_predictions = X_test_prediction), label = 'low'),\n",
    "                                precision_recall(convert_to_classification(input_predictions = y_test), convert_to_classification(input_predictions = X_test_prediction), label = 'moderate'),\n",
    "                                precision_recall(convert_to_classification(input_predictions = y_test), convert_to_classification(input_predictions = X_test_prediction), label = 'high'),\n",
    "                        ]\n",
    "        \n",
    "t1 = time.time()\n",
    "\n",
    "#Return how long the training event took to the user\n",
    "print('Code Segment took',t1 - t0,'seconds to execute.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfbf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an empty dataframe to store the results\n",
    "df_results = df.groupby(['sensor_id']).count().reset_index()\n",
    "df_results = df_results[['sensor_id', 'count']]\n",
    "df_results['sum'] = df_results['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11722e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_results(input_dict):\n",
    "    #Return a df with fold, k value, test and train error as attribtues\n",
    "    sensor_id = []\n",
    "    k_value = []\n",
    "    test = []\n",
    "    train = []\n",
    "    test_accuracy = []\n",
    "    train_accuracy = []\n",
    "    \n",
    "    low_precision = []\n",
    "    low_recall = []\n",
    "    moderate_precision = []\n",
    "    moderate_recall = []\n",
    "    high_precision = []\n",
    "    high_recall = []\n",
    "    \n",
    "    for key in input_dict:\n",
    "        for fold in input_dict[key]:\n",
    "            sensor_id.append(fold)\n",
    "            k_value.append(key)\n",
    "            test.append(input_dict[key][fold][1])\n",
    "            train.append(input_dict[key][fold][0])\n",
    "            test_accuracy.append(input_dict[key][fold][3])\n",
    "            train_accuracy.append(input_dict[key][fold][2])\n",
    "            low_precision.append(input_dict[key][fold][4][0])\n",
    "            low_recall.append(input_dict[key][fold][4][1])\n",
    "            moderate_precision.append(input_dict[key][fold][5][0])\n",
    "            moderate_recall.append(input_dict[key][fold][5][1])\n",
    "            high_precision.append(input_dict[key][fold][6][0])\n",
    "            high_recall.append(input_dict[key][fold][6][1])\n",
    "            \n",
    "    output_df = pd.DataFrame(list(zip(sensor_id, k_value, train, test, train_accuracy, test_accuracy, low_precision, low_recall, moderate_precision, moderate_recall, high_precision, high_recall)),\n",
    "                   columns =['fold', 'k','train_error','test_error','train_accuracy','test_accuracy','low_precision','low_recall','moderate_precision','moderate_recall','high_precision','high_recall'])\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b77813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack the results into a dataframe\n",
    "results = unpack_results(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c99868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge the results into our empty dataframe\n",
    "df_results = results.merge(df_results, how = 'left', left_on = 'fold', right_on = 'sensor_id')\n",
    "df_results = df_results[['fold','k','train_error','test_error','train_accuracy','test_accuracy','low_precision','low_recall','moderate_precision','moderate_recall','high_precision','high_recall','count','sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff3f58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_results = df_results.groupby(['k']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a455420",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df_results.test_accuracy.mean())\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c875d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the results\n",
    "df_results.to_csv('k_'+str(k)+'results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
