import pymysql
import json
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor
import numpy as np

connection = pymysql.connect(host = endpoint, user = username, password = password, db = database_name)

def convert_to_classification(input_predictions):
    output_classes = []

    for item in input_predictions:
        if item < 180:
            output_classes.append('3')
        #elif item < 1200:
        #    output_classes.append('moderate')            
        else:
            output_classes.append('4')

    return output_classes


def parse_coordinates(incoming_string):
    results = []
    incoming_string = incoming_string.replace(' ','')
    
    coordinate_list = incoming_string.split('),(')

    coordinate_list = [x.replace('(','') for x in coordinate_list]
    coordinate_list = [x.replace(')','') for x in coordinate_list]
    coordinate_list = [x.replace('}','') for x in coordinate_list]
    coordinate_list = [x.replace('"','') for x in coordinate_list]
    coordinate_list = [x.replace("'",'') for x in coordinate_list]

    for coords in coordinate_list:
        split_coords = coords.split(',')
        try:
            split_coords = [float(x) for x in split_coords]
        except:
            continue
        
        results.append(tuple(split_coords))

    return results

def lambda_handler(event, context):
    #connetion
    
    waypoints = event['queryStringParameters']['waypoints']
    prediction_x = pd.DataFrame(parse_coordinates(incoming_string = waypoints), columns =['lat','lon'])
    prediction_x['date'] = pd.to_datetime("today").strftime("%Y/%m/%d/ %H")
    prediction_x['unix_time'] = pd.to_datetime(prediction_x.date).astype(np.int64) // 10**9

    prediction_x['month'] = pd.DatetimeIndex(prediction_x['date']).month
    prediction_x['hour'] = pd.DatetimeIndex(prediction_x['date']).hour
    prediction_x['day_of_week'] = pd.DatetimeIndex(prediction_x['date']).dayofweek
    prediction_x['position'] = prediction_x.lon * prediction_x.lat

    prediction_x = prediction_x[['unix_time','hour','month','day_of_week','position']]
    
    cursor = connection.cursor()
    
    #cursor.execute('SELECT * FROM pedestrianCount limit 10')
    sql = 'SELECT * FROM pedestrianCount'
    #sql = "SELECT * FROM `brands`"
    df = pd.read_sql(sql, connection)
    df['date'] = pd.to_datetime(df['unix_time'],unit='s')
    df['position'] = df.lon * df.lat
    df['month'] = df.date.dt.month
    df['day_of_week'] = df.date.dt.dayofweek
    df = df[['sensor_id','count', 'unix_time','hour','month','day_of_week','position','date']]
    
    df_y = df['count']
    df.drop(['count', 'sensor_id','date'], axis = 1, inplace = True)

    ss = StandardScaler()

    df = ss.fit_transform(df)
    prediction_x = ss.transform(prediction_x)

    knn = KNeighborsRegressor(n_neighbors = 9)
    knn.fit(df, df_y)
    
    prediction = convert_to_classification(knn.predict(prediction_x))
    prediction = max(set(prediction), key=prediction.count)
    
    response = {}
    response['result'] = prediction
    response['message'] = 'hello world'
    
    responseObject = {}
    responseObject['statusCode'] = 200
    responseObject['headers'] = {}
    responseObject['headers']['Content-Type'] = 'application/json'
    responseObject['body'] = json.dumps(response)
    
    return responseObject
